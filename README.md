# COVID-19 Death Risk Prediction

![CDC Logo](https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/US_CDC_logo.svg/300px-US_CDC_logo.svg.png)

## About The Project

This project was completed when I studied Data Analytics during my MSc. The objective was to build a data model to understand and predict death risk associated with COVID-19, using real-world case surveillance data collected by the CDC.

The task was divided into two main stages, with one notebook corresponding to each:

## Data Understanding & Preparation
I was provided with anonymised patient records containing demographic, clinical, and outcome information. From this, I:
+ Produced a data quality report
+ Outlined a systematic data cleaning and transformation plan
+ Performed exploratory feature analysis
+Created domain-informed features for predictive modelling

## Model Training & Evaluation
Using the cleaned and engineered dataset, I explored how models may be used to identify patients at risk of death. Some tasks included: 

+ Training logistic regression, linear regression and Random Forest models on the dataset.
+ Evaluating the performance of each model using appropriate metrics (precision, accuracy, F1 score).
+ Identify strengths and limitations of each model's performance.
+ Recommended improvements based on model outcomes, as well as new features that could be generated by integrating additional data

## Repository Structure

```bash
Covid19_DeathRiskPrediction/
│
├── data/                         # All CSVs used in the project.
│   ├── raw                       # The inital CSV file provided to me.
│   └── cleaned_data              # The product of the initial data cleaning.
│   └── test_train_data           # 30% of the cleaned dataset, reserved for testing against models 
│
├── notebooks/                    # Analysis steps (conducted in Jupyter Notebook)
│   ├── Homework1.ipynb           # Details the data cleaning and processing. 
│   ├── Homework2.ipynb           # Training, testing and evaluating various models on the dataset.
│
├── reports/             
│   ├── data_quality_report.pdf    # Details the quality issues in the original dataset.
│   └── data_quality_plan.pdf      # Outlines steps that will be taken to rectify the above. 
```

## Features

- Data audit and cleaning of real-world CDC COVID-19 data.
- Visual and statistical exploration of categorical and continuous variables.
- Identification and handling of missing, duplicate, and constant values.
- Justified data quality improvement strategies.
- Creation of novel features based on domain knowledge.
- Structured project artifacts: code, outputs, and PDF reports.

## Dataset

Data sourced from the [CDC COVID-19 Case Surveillance Public Use Dataset](https://data.cdc.gov/Case-Surveillance/COVID-19-Case-Surveillance-Public-Use-Data-with-Ge/n8mc-b4w4). 

Each student worked with a unique, anonymised subset. The specific subsection of data I worked with was selected by my lecturer and is available in this repo, at data/raw . 

My dataset contains 50,000 records and includes both survivors and non-survivors.

## Built With 

This project was developed in Python, using the following core packages:

- `pandas`, `numpy` – Data manipulation
- `matplotlib`, `seaborn` – Visualization
- `scikit-learn` – Feature engineering and modeling
- `jupyter` – Notebook-based development and presentation
